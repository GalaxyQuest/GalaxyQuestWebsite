<script>
    $("#optimizing").css("font-weight", "bold")
</script>
<div class="container index">
  <div class="chapterTitle">
    <h2>Chapter 4: Optimizing our Machine and Travelling Into Space</h2>
  </div>
<div class="row featurette">
  <div class="col-md-5">
    <div class="chart">
      <div class="errorChart"></div>
    </div>
  </div>
  <div class="col-md-7">
      <h2 class="featurette-heading">Our Heroes' Progress</h2>
  </div>
  <p class="lead">The machine's error margin steadily decreased as our heroes discovered new features and adjusted parameters.</p>
</div>
<hr class="featurette-divider">
<div class="row">
  <h3 class="pull-left">Our Heroes' Epic Battle with Error Margins</h4><br><br><br><br>
      <ul>
        <li><h4 class="text-info">Playing with the Algorithm's Parameters</h4>
          <ul><li>The parameters that may be adjusted in a Random Forests algorithm include the number of trees used, maximum tree depth, the number of features to use, and the size of the subset of features each tree can choose from. Our heroes adjusted these parameters to try and find an optimal algorithm configuration for their problem.</ul></li>
        <li><h4 class="text-info">Adding to our Feature Arsenal</h4>
          <ul><li>Our heroes added additional input features to feed to their learning algorithm that they thought would decrease the generalization error observed once the algorithm was trained. Measuring generalization error for each of the different outputs they produced gave them an idea of what they could improve. Sometimes adding features that seemed helpful actually ended up increasing their generalization error. Our heroes hypothesize that this was the case because the new features may have been increasing their model's bias towards those features of the data.</ul></li>
        </li></li>
</div>

<hr class="featurette-divider">
<div class="row">

  <h3 class="pull-right">Lessons Learned and Discovered Best Practices</h4><br><br><br><br>
      <ul>
        <li><h4 class="text-info">Avoid Overfitting and Underfitting</h4>
          <ul><li>Measuring training and test error of your current algorithm can help you understand whether you are having an overfitting or underfitting problem. Both the algorithm's parameters and input features can affect overfitting and underfitting. Overfitting will give you a low margin of error with your training set, but it will not produce a great result when you introduce new data. Underfitting will generally give you a high margin of error across both training and new data. Use this information to understand what parameters need adjustment in your algorithm.</ul></li></li>

</div>
<script src="../scripts/c3chart.js"></script>
